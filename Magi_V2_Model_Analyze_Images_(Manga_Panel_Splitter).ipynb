{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyN4TK77Y6gT+U8o7pALFE+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curlos/manga-panel-splitter/blob/main/Magi_V2_Model_Analyze_Images_(Manga_Panel_Splitter).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lCw9MUarnqyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRJQAOPwsmrS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.40 pulp pyngrok python-dotenv accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok"
      ],
      "metadata": {
        "id": "ZYtUBVUwa6IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from flask import Flask, request, jsonify\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import base64\n",
        "import pdb\n",
        "from google.colab import drive\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Mount Google Drive if it hasn't mounted already.\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Path to the .env file in your Drive\n",
        "env_path = '/content/drive/MyDrive/google_colab_env_files/.env'\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(env_path)\n",
        "\n",
        "# Access the ngrok auth token\n",
        "ngrok_auth_token = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "if not ngrok_auth_token:\n",
        "    raise ValueError(\"NGROK_AUTH_TOKEN is not set. Check your .env file in Google Drive ('google_colab_env_files/.env').\")\n",
        "\n",
        "ngrok.set_auth_token(ngrok_auth_token)\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # Increase limit to 16MB\n",
        "\n",
        "# Initialize the Magi model\n",
        "magi_model = AutoModel.from_pretrained(\n",
        "            \"ragavsachdeva/magiv2\", trust_remote_code=True).eval()\n",
        "\n",
        "def get_per_page_results(magi_model, chapter_pages, character_bank):\n",
        "  # Set to \"no_grad()\" so that there's inference without tracking gradients. Basically, this saves memory and computational resources by turning off gradient tracking.\n",
        "  with torch.no_grad():\n",
        "      per_page_results = magi_model.do_chapter_wide_prediction(\n",
        "          chapter_pages, character_bank, use_tqdm=True, do_ocr=True\n",
        "      )\n",
        "\n",
        "  return per_page_results\n",
        "\n",
        "@app.route('/process-images-with-magi-model', methods=['POST'])\n",
        "def process_images_with_magi_model():\n",
        "    try:\n",
        "      # Parse JSON payload\n",
        "      request_data = request.json\n",
        "      encoded_arrays = request_data.get(\"chapter_pages_image_numpy_array\")\n",
        "      character_bank = request_data.get(\"character_bank\")\n",
        "\n",
        "      pdb.set_trace()\n",
        "\n",
        "      # Decode and reconstruct the arrays\n",
        "      chapter_pages_image_numpy_array = [\n",
        "          np.frombuffer(base64.b64decode(item[\"data\"]), dtype=item[\"dtype\"]).reshape(item[\"shape\"])\n",
        "          for item in encoded_arrays\n",
        "      ]\n",
        "\n",
        "      # Run Magi model on the file\n",
        "      per_page_results = get_per_page_results(\n",
        "          magi_model, chapter_pages_image_numpy_array, character_bank\n",
        "      )\n",
        "\n",
        "      pdb.set_trace()\n",
        "\n",
        "      return per_page_results\n",
        "    except Exception as e:\n",
        "      return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/hello-world', methods=['GET'])\n",
        "def hello_world():\n",
        "    return 'Hello World!'\n",
        "\n",
        "    # Send back the processed numpy array\n",
        "    # return jsonify({\"processed_array\": processed_array.tolist()})\n",
        "\n",
        "def run_flask():\n",
        "  # Run Flask app without reloader (important for threading)\n",
        "  app.run(host=\"0.0.0.0\", port=8893, debug=True, use_reloader=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Start Flask in a thread to prevent blocking\n",
        "    thread = threading.Thread(target=run_flask)\n",
        "    thread.start()\n",
        "\n",
        "    # Expose the Flask app to the internet using ngrok\n",
        "    public_url = ngrok.connect(8893)\n",
        "    print(\"Public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "spWkLnG1CATy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}