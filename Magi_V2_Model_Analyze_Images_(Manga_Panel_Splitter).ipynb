{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyN4TK77Y6gT+U8o7pALFE+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curlos/manga-panel-splitter/blob/main/Magi_V2_Model_Analyze_Images_(Manga_Panel_Splitter).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lCw9MUarnqyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRJQAOPwsmrS",
        "outputId": "acecae3a-cd87-4780-f5a8-30d52ed93aab",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.40 in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: pulp in /usr/local/lib/python3.10/dist-packages (2.9.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.40 pulp pyngrok python-dotenv accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok"
      ],
      "metadata": {
        "id": "ZYtUBVUwa6IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from flask import Flask, request, jsonify\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import base64\n",
        "import pdb\n",
        "from google.colab import drive\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Mount Google Drive if it hasn't mounted already.\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Path to the .env file in your Drive\n",
        "env_path = '/content/drive/MyDrive/google_colab_env_files/.env'\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(env_path)\n",
        "\n",
        "# Access the ngrok auth token\n",
        "ngrok_auth_token = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "if not ngrok_auth_token:\n",
        "    raise ValueError(\"NGROK_AUTH_TOKEN is not set. Check your .env file in Google Drive ('google_colab_env_files/.env').\")\n",
        "\n",
        "ngrok.set_auth_token(ngrok_auth_token)\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # Increase limit to 16MB\n",
        "\n",
        "# Initialize the Magi model\n",
        "magi_model = AutoModel.from_pretrained(\n",
        "            \"ragavsachdeva/magiv2\", trust_remote_code=True).eval()\n",
        "\n",
        "def get_per_page_results(magi_model, chapter_pages, character_bank):\n",
        "  # Set to \"no_grad()\" so that there's inference without tracking gradients. Basically, this saves memory and computational resources by turning off gradient tracking.\n",
        "  with torch.no_grad():\n",
        "      per_page_results = magi_model.do_chapter_wide_prediction(\n",
        "          chapter_pages, character_bank, use_tqdm=True, do_ocr=True\n",
        "      )\n",
        "\n",
        "  return per_page_results\n",
        "\n",
        "@app.route('/process-images-with-magi-model', methods=['POST'])\n",
        "def process_images_with_magi_model():\n",
        "    try:\n",
        "      # Parse JSON payload\n",
        "      request_data = request.json\n",
        "      encoded_arrays = request_data.get(\"chapter_pages_image_numpy_array\")\n",
        "      character_bank = request_data.get(\"character_bank\")\n",
        "\n",
        "      pdb.set_trace()\n",
        "\n",
        "      # Decode and reconstruct the arrays\n",
        "      chapter_pages_image_numpy_array = [\n",
        "          np.frombuffer(base64.b64decode(item[\"data\"]), dtype=item[\"dtype\"]).reshape(item[\"shape\"])\n",
        "          for item in encoded_arrays\n",
        "      ]\n",
        "\n",
        "      # Run Magi model on the file\n",
        "      per_page_results = get_per_page_results(\n",
        "          magi_model, chapter_pages_image_numpy_array, character_bank\n",
        "      )\n",
        "\n",
        "      pdb.set_trace()\n",
        "\n",
        "      return per_page_results\n",
        "    except Exception as e:\n",
        "      return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/hello-world', methods=['GET'])\n",
        "def hello_world():\n",
        "    return 'Hello World!'\n",
        "\n",
        "    # Send back the processed numpy array\n",
        "    # return jsonify({\"processed_array\": processed_array.tolist()})\n",
        "\n",
        "def run_flask():\n",
        "  # Run Flask app without reloader (important for threading)\n",
        "  app.run(host=\"0.0.0.0\", port=8893, debug=True, use_reloader=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Start Flask in a thread to prevent blocking\n",
        "    thread = threading.Thread(target=run_flask)\n",
        "    thread.start()\n",
        "\n",
        "    # Expose the Flask app to the internet using ngrok\n",
        "    public_url = ngrok.connect(8893)\n",
        "    print(\"Public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spWkLnG1CATy",
        "outputId": "706cc7f4-2fa7-4e57-f19f-2c4586332ffa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2qwDNm81vHgbdQn94RYAiyt2R2V_6JUmhkXmm4ZzbyqwBcBu1\n",
            "Magiv2Model(\n",
            "  (ocr_model): VisionEncoderDecoderModel(\n",
            "    (encoder): ViTModel(\n",
            "      (embeddings): ViTEmbeddings(\n",
            "        (patch_embeddings): ViTPatchEmbeddings(\n",
            "          (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (encoder): ViTEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0-11): 12 x ViTLayer(\n",
            "            (attention): ViTAttention(\n",
            "              (attention): ViTSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=False)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=False)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=False)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (output): ViTSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): ViTIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): ViTOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (pooler): ViTPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (decoder): TrOCRForCausalLM(\n",
            "      (model): TrOCRDecoderWrapper(\n",
            "        (decoder): TrOCRDecoder(\n",
            "          (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
            "          (embed_positions): TrOCRLearnedPositionalEmbedding(514, 1024)\n",
            "          (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (layers): ModuleList(\n",
            "            (0-11): 12 x TrOCRDecoderLayer(\n",
            "              (self_attn): TrOCRAttention(\n",
            "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              )\n",
            "              (activation_fn): GELUActivation()\n",
            "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (encoder_attn): TrOCRAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
            "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              )\n",
            "              (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (output_projection): Linear(in_features=1024, out_features=50265, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (crop_embedding_model): ViTMAEModel(\n",
            "    (embeddings): ViTMAEEmbeddings(\n",
            "      (patch_embeddings): ViTMAEPatchEmbeddings(\n",
            "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "      )\n",
            "    )\n",
            "    (encoder): ViTMAEEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ViTMAELayer(\n",
            "          (attention): ViTMAEAttention(\n",
            "            (attention): ViTMAESelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (output): ViTMAESelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ViTMAEIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ViTMAEOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (detection_transformer): ConditionalDetrModel(\n",
            "    (backbone): ConditionalDetrConvModel(\n",
            "      (conv_encoder): ConditionalDetrConvEncoder(\n",
            "        (model): FeatureListNet(\n",
            "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "          (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "          (act1): ReLU(inplace=True)\n",
            "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "          (layer1): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "              (downsample): Sequential(\n",
            "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (layer2): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "              (downsample): Sequential(\n",
            "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                (1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "            (3): Bottleneck(\n",
            "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (layer3): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "              (downsample): Sequential(\n",
            "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                (1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "            (3): Bottleneck(\n",
            "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "            (4): Bottleneck(\n",
            "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "            (5): Bottleneck(\n",
            "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (layer4): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "              (downsample): Sequential(\n",
            "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                (1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn1): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act1): ReLU(inplace=True)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn2): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (drop_block): Identity()\n",
            "              (act2): ReLU(inplace=True)\n",
            "              (aa): Identity()\n",
            "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn3): ConditionalDetrFrozenBatchNorm2d()\n",
            "              (act3): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (position_embedding): ConditionalDetrSinePositionEmbedding()\n",
            "    )\n",
            "    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (query_position_embeddings): Embedding(305, 256)\n",
            "    (encoder): ConditionalDetrEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x ConditionalDetrEncoderLayer(\n",
            "          (self_attn): DetrAttention(\n",
            "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): ConditionalDetrDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): ConditionalDetrDecoderLayer(\n",
            "          (sa_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (sa_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (sa_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (sa_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (sa_v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (self_attn): ConditionalDetrAttention(\n",
            "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (ca_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_qpos_sine_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (encoder_attn): ConditionalDetrAttention(\n",
            "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1-5): 5 x ConditionalDetrDecoderLayer(\n",
            "          (sa_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (sa_qpos_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (sa_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (sa_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (sa_v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (self_attn): ConditionalDetrAttention(\n",
            "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (ca_qcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_qpos_proj): None\n",
            "          (ca_kcontent_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_kpos_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (ca_qpos_sine_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (encoder_attn): ConditionalDetrAttention(\n",
            "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (query_scale): MLP(\n",
            "        (layers): ModuleList(\n",
            "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (ref_point_head): MLP(\n",
            "        (layers): ModuleList(\n",
            "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (1): Linear(in_features=256, out_features=2, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bbox_predictor): ConditionalDetrMLPPredictionHead(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
            "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (character_character_matching_head): ConditionalDetrMLPPredictionHead(\n",
            "    (layers): ModuleList(\n",
            "      (0): Linear(in_features=2304, out_features=256, bias=True)\n",
            "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (2): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (text_character_matching_head): ConditionalDetrMLPPredictionHead(\n",
            "    (layers): ModuleList(\n",
            "      (0): Linear(in_features=768, out_features=256, bias=True)\n",
            "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (2): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (text_tail_matching_head): ConditionalDetrMLPPredictionHead(\n",
            "    (layers): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (2): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (class_labels_classifier): Linear(in_features=256, out_features=4, bias=True)\n",
            "  (is_this_text_a_dialogue): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (matcher): ConditionalDetrHungarianMatcher()\n",
            ")\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 8893 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://8a94-35-198-207-72.ngrok-free.app\" -> \"http://localhost:8893\"\n"
          ]
        }
      ]
    }
  ]
}